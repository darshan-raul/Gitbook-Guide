# Fine tuning

Fine-tuning is the process of taking a pre-trained model and training it further on a smaller, specific dataset to adapt it to a particular task.

* **Methodology:**
  * Uses **supervised learning** with labeled data.
  * The model starts from a pre-trained state (e.g., a large language model like GPT) and is further trained on domain-specific or task-specific data.
  * Only a subset of the modelâ€™s parameters might be updated, or the entire model might be trained with a lower learning rate.
* **Example Use Cases:**
  * Adapting a general-purpose language model to legal or medical text.
  * Customizing an image classification model for a specific dataset.
* **Advantages:**
  * Requires **less data** and computational resources compared to training from scratch.
  * Improves performance on **specific** domains or tasks.

Fine-tuning might be useful to you if you need:

* to customize your model to specific business needs
* your model to successfully work with domain-specific language, such as industry jargon, technical terms, or other specialized vocabulary
* enhanced performance for specific tasks
* accurate, relative, and context-aware responses in applications
* responses that are more factual, less toxic, and better-aligned to specific requirements
